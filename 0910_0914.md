# 0912


![](pics/0912_vp_loss.png)

![](pics/0912_doce_coef.png)

The training is still okay, and the results seems being better with epochs increasing.


<video data-autoplay width="300" height="300">
    <source src="job_apply_uisee/vp_data_demo/predict_video_weights.0050.h5_0912_19_03.mp4" type="video/mp4">
</video>
<video data-autoplay width="300" height="300">
    <source src="job_apply_uisee/vp_data_demo/predict_video_weights.0150.h5_0912_18_32.mp4" type="video/mp4">
</video>
<video data-autoplay width="300" height="300">
    <source src="job_apply_uisee/vp_data_demo/predict_video_weights.0250.h5_0912_18_03.mp4" type="video/mp4">
</video>


TODO:
* Try to regress the point directly


# 0911

After 50 epochs, I use the saved weights and test one no related video (not seen in the train/test dataset, even the color is slightly different). The results as shown below is impressive (to me), weiqiang said maybe should try regression first and establish one baseline.

![](pics/vp_seg_50_epochs.mp4)

TODO:
* Let the model train more time and see whether the performance will gain at some of the hard scenarios in the video
* Change for different training mechanism


# 0910

Together with yesterday:

[http://gitlab.hobot.cc/dongxu.miao/vp_seg_unet](http://gitlab.hobot.cc/dongxu.miao/vp_seg_unet)

* Generate mask images as shown below

![](pics/vp_para_2.png)

* Split train(0.8)/test(0.2) from `EASY` and `OCCUPIED` type
* Managed to run one UNet model on the VP, change code from [https://github.com/tkwoo/visualization-segmentation-process](https://github.com/tkwoo/visualization-segmentation-process)
* Re-run with validation and plotting with tensorboard

Some results:

Seems nice:

![](pics/vp_seg_01.png)

![](pics/vp_seg_01.png)

Some video demos:

Two train images:

![](pics/train_19700101_080756_057_4.jpg.mp4)

![](pics/train_19700101_082034_105.jpg.mp4)

Two test:

![](pics/test_2017-10-20-15-49-13_029500.png.mp4)

![](pics/test_19700101_080739_389_4.jpg.mp4)


